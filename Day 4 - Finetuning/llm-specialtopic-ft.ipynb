{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Step 1: Install all the needed packages"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:14:01.705102Z","iopub.status.busy":"2024-08-02T16:14:01.704327Z","iopub.status.idle":"2024-08-02T16:14:01.710110Z","shell.execute_reply":"2024-08-02T16:14:01.709201Z","shell.execute_reply.started":"2024-08-02T16:14:01.705070Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-08-02T16:14:04.201096Z","iopub.status.busy":"2024-08-02T16:14:04.200718Z","iopub.status.idle":"2024-08-02T16:14:16.696763Z","shell.execute_reply":"2024-08-02T16:14:16.695704Z","shell.execute_reply.started":"2024-08-02T16:14:04.201066Z"},"trusted":true},"outputs":[],"source":["!pip install -q accelerate peft bitsandbytes transformers trl"]},{"cell_type":"markdown","metadata":{},"source":["# Step 2: Import all the Required Libraries"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:14:43.114784Z","iopub.status.busy":"2024-08-02T16:14:43.113439Z","iopub.status.idle":"2024-08-02T16:14:43.120248Z","shell.execute_reply":"2024-08-02T16:14:43.119164Z","shell.execute_reply.started":"2024-08-02T16:14:43.114746Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","from datasets import load_dataset\n","from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    pipeline,\n","    EarlyStoppingCallback\n",")\n","from peft import LoraConfig, prepare_model_for_kbit_training, get_peft_model\n","from trl import SFTTrainer"]},{"cell_type":"markdown","metadata":{},"source":["# Step 3: Get the model names and dataset names"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:14:45.659538Z","iopub.status.busy":"2024-08-02T16:14:45.659159Z","iopub.status.idle":"2024-08-02T16:14:45.664204Z","shell.execute_reply":"2024-08-02T16:14:45.663248Z","shell.execute_reply.started":"2024-08-02T16:14:45.659507Z"},"trusted":true},"outputs":[],"source":["model_name = 'NousResearch/Llama-2-7b-chat-hf'\n","dataset_name = 'mlabonne/guanaco-llama2'\n","new_model = 'Llama-2-7b-hf-chat-finetune'"]},{"cell_type":"markdown","metadata":{},"source":["# Step 4: Load the dataset and model"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:14:47.818394Z","iopub.status.busy":"2024-08-02T16:14:47.818024Z","iopub.status.idle":"2024-08-02T16:14:52.850947Z","shell.execute_reply":"2024-08-02T16:14:52.850024Z","shell.execute_reply.started":"2024-08-02T16:14:47.818365Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ab93e37897d74b6b896d7531fd31ad47","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/8.99M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"353282bbd9fb4a96b2d0a1b593e8831c","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/476k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c2dc94a3ccc3457ba41e8626d026b062","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/9846 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96671d41e3434fb997860d38e6fbc130","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/518 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dataset = load_dataset(dataset_name, split = 'train')\n","dataset = dataset.shuffle(seed=42).select(range(200))\n","\n","train_test_split = dataset.train_test_split(test_size=50)\n","train_dataset = train_test_split['train']\n","eval_dataset = train_test_split['test']"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:14:57.715304Z","iopub.status.busy":"2024-08-02T16:14:57.714945Z","iopub.status.idle":"2024-08-02T16:14:57.724488Z","shell.execute_reply":"2024-08-02T16:14:57.723389Z","shell.execute_reply.started":"2024-08-02T16:14:57.715276Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["150 50 {'text': '<s>[INST] –†–∞—Å—Å–∫–∞–∂–∏ –ø—Ä–æ –∞—Ç–∞–∫—É –Ω–∞ –ë–∏—Å–º–∞—Ä–∫ [/INST] –ê—Ç–∞–∫–∞ –Ω–∞ –ë–∏—Å–º–∞—Ä–∫ ‚Äì —ç—Ç–æ —Å–æ–±—ã—Ç–∏–µ –í—Ç–æ—Ä–æ–π –º–∏—Ä–æ–≤–æ–π –≤–æ–π–Ω—ã, –ø—Ä–æ–∏–∑–æ—à–µ–¥—à–µ–µ –≤ –º–∞–µ 1941 –≥–æ–¥–∞, –∫–æ–≥–¥–∞ –±—Ä–∏—Ç–∞–Ω—Å–∫–∏–π —Ñ–ª–æ—Ç –∞—Ç–∞–∫–æ–≤–∞–ª –Ω–µ–º–µ—Ü–∫–∏–π –ª–∏–Ω–∫–æ—Ä \"–ë–∏—Å–º–∞—Ä–∫\" –≤ –ê—Ç–ª–∞–Ω—Ç–∏–∫–µ.\\n\\n–õ–∏–Ω–∫–æ—Ä \"–ë–∏—Å–º–∞—Ä–∫\" –±—ã–ª –æ–¥–Ω–∏–º –∏–∑ —Å–∞–º—ã—Ö –º–æ—â–Ω—ã—Ö –∏ –æ–ø–∞—Å–Ω—ã—Ö –∫–æ—Ä–∞–±–ª–µ–π —Å–≤–æ–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏. –í –º–∞–µ 1941 –≥–æ–¥–∞ \"–ë–∏—Å–º–∞—Ä–∫\" –≤–º–µ—Å—Ç–µ —Å –¥—Ä—É–≥–∏–º –ª–∏–Ω–∫–æ—Ä–æ–º \"–ü—Ä–∏–Ω—Ü –ï–≤–≥–µ–Ω–∏–π\" –ø—ã—Ç–∞–ª–∏—Å—å –ø—Ä–æ—Ä–≤–∞—Ç—å—Å—è –≤ –ê—Ç–ª–∞–Ω—Ç–∏–∫—É, —á—Ç–æ–±—ã –ø—Ä–µ—Ä–≤–∞—Ç—å —Å–Ω–∞–±–∂–µ–Ω–∏–µ —Å–æ—é–∑–Ω–∏–∫–æ–≤ –ì–µ—Ä–º–∞–Ω–∏–∏, –∞ —Ç–∞–∫–∂–µ –∞—Ç–∞–∫–æ–≤–∞—Ç—å —Å–æ—é–∑–Ω—ã–µ –∫–æ—Ä–∞–±–ª–∏.\\n\\n–ë—Ä–∏—Ç–∞–Ω—Å–∫–∏–π —Ñ–ª–æ—Ç, –ø–æ–ª—É—á–∏–≤ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–≤–∏–∂–µ–Ω–∏–∏ \"–ë–∏—Å–º–∞—Ä–∫–∞\", —Ä–µ—à–∏–ª –ø—Ä–µ—Å–µ—á—å –µ–≥–æ –ø–æ–ø—ã—Ç–∫–∏ –ø—Ä–æ—Ä–≤–∞—Ç—å—Å—è –≤ –ê—Ç–ª–∞–Ω—Ç–∏–∫—É. –ë—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–≤–µ —ç—Å–∫–∞–¥—Ä—ã ‚Äì –ø–µ—Ä–≤–∞—è, –≤ —Å–æ—Å—Ç–∞–≤–µ –∫–æ—Ç–æ—Ä–æ–π –±—ã–ª–∏ –ª–∏–Ω–∫–æ—Ä—ã \"–•—É–¥\" –∏ \"–ü—Ä–∏—Ü–µ—Å—Å –†–æ—è–ª\", –∞ —Ç–∞–∫–∂–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫—Ä–µ–π—Å–µ—Ä–æ–≤, –∞ –≤—Ç–æ—Ä–∞—è, –±–æ–ª–µ–µ –∫—Ä—É–ø–Ω–∞—è, –∫–æ—Ç–æ—Ä–∞—è –≤–∫–ª—é—á–∞–ª–∞ –≤ —Å–µ–±—è –±–æ–µ–≤—ã–µ –∫–æ—Ä–∞–±–ª–∏ \"–í–∏–∫—Ç–æ—Ä–∏—É—Å\", \"–†–æ–¥–Ω–µ–π\", \"–ù–æ—Ä—Ñ–æ–ª–∫\" –∏ \"–°—É—Ñ—Ñ–æ–ª–∫\".\\n\\n–ü–æ—Å–ª–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –¥–Ω–µ–π –ø–æ–≥–æ–Ω–∏, \"–ë–∏—Å–º–∞—Ä–∫\" –±—ã–ª –ø–æ—Ä–∞–∂–µ–Ω —Ç–æ—Ä–ø–µ–¥–æ–π –±—Ä–∏—Ç–∞–Ω—Å–∫–æ–≥–æ —Å–∞–º–æ–ª–µ—Ç–∞ \"–°–∫–æ—Ä–ø–∏–æ–Ω\" –∏ —Ç–µ—Ä–ø–µ–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏—è. –ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —ç—Ç–æ, –æ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞–ª –±–æ—Ä—å–±—É, –Ω–æ –≤ –∫–æ–Ω–µ—á–Ω–æ–º –∏—Ç–æ–≥–µ –±—ã–ª –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –±—Ä–∏—Ç–∞–Ω—Å–∫–∏–º–∏ –∫–æ—Ä–∞–±–ª—è–º–∏ –∏ –∑–∞—Ç–æ–ø–ª–µ–Ω. –í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —ç—Ç–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –±—ã–ª —É–Ω–∏—á—Ç–æ–∂–µ–Ω –æ–¥–∏–Ω –∏–∑ —Å–∞–º—ã—Ö –º–æ—â–Ω—ã—Ö –∫–æ—Ä–∞–±–ª–µ–π –í—Ç–æ—Ä–æ–π –º–∏—Ä–æ–≤–æ–π –≤–æ–π–Ω—ã.\\n\\n–ê—Ç–∞–∫–∞ –Ω–∞ –ë–∏—Å–º–∞—Ä–∫ —Å—Ç–∞–ª–∞ –æ–¥–Ω–æ–π –∏–∑ –∫—Ä—É–ø–Ω–µ–π—à–∏—Ö –º–æ—Ä—Å–∫–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –í—Ç–æ—Ä–æ–π –º–∏—Ä–æ–≤–æ–π –≤–æ–π–Ω—ã –∏ —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ–¥–Ω–∏–º –∏–∑ –≥–ª–∞–≤–Ω—ã—Ö —É—Å–ø–µ—Ö–æ–≤ –±—Ä–∏—Ç–∞–Ω—Å–∫–æ–≥–æ —Ñ–ª–æ—Ç–∞. –û–Ω–∞ –ø–æ–∫–∞–∑–∞–ª–∞, —á—Ç–æ –¥–∞–∂–µ —Å–∞–º—ã–µ –º–æ—â–Ω—ã–µ –∫–æ—Ä–∞–±–ª–∏ –Ω–µ –º–æ–≥—É—Ç –≤—ã–∂–∏—Ç—å –±–µ–∑ –ø–æ–¥–¥–µ—Ä–∂–∫–∏ —Å–æ—é–∑–Ω–∏–∫–æ–≤ –∏ —á—Ç–æ –±—Ä–∏—Ç–∞–Ω—Å–∫–∏–π —Ñ–ª–æ—Ç –±—ã–ª —Å–ø–æ—Å–æ–±–µ–Ω –Ω–∞–Ω–µ—Å—Ç–∏ —É–¥–∞—Ä –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ –º–∏—Ä–æ–≤–æ–≥–æ –æ–∫–µ–∞–Ω–∞. </s>\\\\\\n<s>[INST] –ê —á—Ç–æ —Å–ª—É—á–∏–ª–æ—Å—å —Å –ì–∏–Ω–¥–µ–Ω–±—É—Ä–≥–æ–º? [/INST] –ü–æ-–≤–∏–¥–∏–º–æ–º—É, –≤—ã –∏–º–µ–µ—Ç–µ –≤ –≤–∏–¥—É –∫—Ä—É–ø–Ω–µ–π—à–∏–π –≤–æ–∑–¥—É—à–Ω—ã–π –ª–∞–π–Ω–µ—Ä —Å–≤–æ–µ–≥–æ –≤—Ä–µ–º–µ–Ω–∏, –Ω–µ–º–µ—Ü–∫–∏–π –¥–∏—Ä–∏–∂–∞–±–ª—å \"–ì–∏–Ω–¥–µ–Ω–±—É—Ä–≥\" (LZ 129), –∫–æ—Ç–æ—Ä—ã–π –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ—ã –≤ –ù—å—é-–î–∂–µ—Ä—Å–∏, –°–®–ê, 6 –º–∞—è 1937 –≥–æ–¥–∞ –±—ã–ª —É–Ω–∏—á—Ç–æ–∂–µ–Ω –æ–≥–Ω–µ–º. –ö–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –≤–æ –≤—Ä–µ–º—è –ø—Ä–∏–∑–µ–º–ª–µ–Ω–∏—è, –∫–æ–≥–¥–∞ –ª–∞–π–Ω–µ—Ä –≤–Ω–µ–∑–∞–ø–Ω–æ –∑–∞–≥–æ—Ä–µ–ª—Å—è –∏ —Ä–∞–∑—Ä—É—à–∏–ª—Å—è –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥, –ø–æ–≥–∏–±–ª–∏ 36 —á–µ–ª–æ–≤–µ–∫. –ü—Ä–∏—á–∏–Ω–∞ –ø–æ–∂–∞—Ä–∞ –¥–æ —Å–∏—Ö –ø–æ—Ä –æ—Å—Ç–∞–µ—Ç—Å—è –Ω–µ—è—Å–Ω–æ–π, —Ö–æ—Ç—è –±—ã–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω—ã —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Ç–µ–æ—Ä–∏–∏, –≤–∫–ª—é—á–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≥–µ–ª–∏—è, –≤–∑—Ä—ã–≤ –Ω–µ—Ñ—Ç—è–Ω—ã—Ö –ø–∞—Ä–æ–≤ –∏–ª–∏ –¥–∞–∂–µ –∞–∫—Ç —Å–∞–±–æ—Ç–∞–∂–∞. –ö–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞ \"–ì–∏–Ω–¥–µ–Ω–±—É—Ä–≥–∞\" —Å—Ç–∞–ª–∞ –æ–¥–Ω–∏–º –∏–∑ —Å–∞–º—ã—Ö —Ç—Ä–∞–≥–∏—á–µ—Å–∫–∏—Ö —Å–æ–±—ã—Ç–∏–π –≤ –∏—Å—Ç–æ—Ä–∏–∏ –∞–≤–∏–∞—Ü–∏–∏ –∏ —Å—Ç–∞–ª–∞ –ø—Ä–∏—á–∏–Ω–æ–π –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω–æ–≥–æ —É–ø–∞–¥–∫–∞ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –¥–∏—Ä–∏–∂–∞–±–ª–µ–π –∫–∞–∫ —Å—Ä–µ–¥—Å—Ç–≤–∞ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–æ–≥–æ –ø–∞—Å—Å–∞–∂–∏—Ä—Å–∫–æ–≥–æ —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–∞. </s>'}\n"]}],"source":["print(len(train_dataset), len(eval_dataset), train_dataset[0])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:15:00.282777Z","iopub.status.busy":"2024-08-02T16:15:00.282369Z","iopub.status.idle":"2024-08-02T16:15:00.289588Z","shell.execute_reply":"2024-08-02T16:15:00.288352Z","shell.execute_reply.started":"2024-08-02T16:15:00.282746Z"},"trusted":true},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit = True,\n","    bnb_4bit_quant_type='nf4',\n","    bnb_4bit_compute_dtype=torch.float16,\n","    bnb_4bit_use_double_quant = True\n",")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:15:02.239115Z","iopub.status.busy":"2024-08-02T16:15:02.238699Z","iopub.status.idle":"2024-08-02T16:16:22.607903Z","shell.execute_reply":"2024-08-02T16:16:22.607083Z","shell.execute_reply.started":"2024-08-02T16:15:02.239081Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b3d9c8bf26f40c18d85ee9c446442c2","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ea9150b3b1894a91bd7116297eedb979","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f407bcea59e4be4b6b795d99448eac6","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d4dd552101be4fa78eae111a19d991c8","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5aed6b8f1f1b410eb33455fca890a262","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"979fd8c17f8f4a87a2d41f41946fb4d2","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f68a4c912b84e88bc012942e2c89361","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"de881546420344428d261bfaabb309c9","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/746 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"58bccca19acc4187bd5724233021225a","version_major":2,"version_minor":0},"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"96bbf5ec12484552afeeb7151fd95443","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1bb4e3251f9e42f88ec596f1f239a6e9","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/21.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"68cf1a7e718b474e9c783c62f719a416","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/435 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# loading the base model\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    quantization_config = bnb_config,\n","    device_map = 'auto',\n","    token = ''\n",")\n","\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1    # more accurate but slower computation\n","\n","# Loading LLaMa tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, token='key_here')\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = 'right'    # Fix weird overflow issue with fp16 training"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:16:23.263395Z","iopub.status.busy":"2024-08-02T16:16:23.263129Z","iopub.status.idle":"2024-08-02T16:16:26.086638Z","shell.execute_reply":"2024-08-02T16:16:26.085488Z","shell.execute_reply.started":"2024-08-02T16:16:23.263373Z"},"trusted":true},"outputs":[],"source":["# Load LoRA configuration\n","peft_config = LoraConfig(\n","    lora_alpha = 16,\n","    lora_dropout = 0.1,\n","    r = 64,\n","    bias = 'none',\n","    task_type = \"CAUSAL_LM\")\n","\n","model = prepare_model_for_kbit_training(model)\n","model = get_peft_model(model,peft_config)"]},{"cell_type":"markdown","metadata":{},"source":["# Step 5: Training"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:16:29.553566Z","iopub.status.busy":"2024-08-02T16:16:29.553179Z","iopub.status.idle":"2024-08-02T16:16:29.590729Z","shell.execute_reply":"2024-08-02T16:16:29.589816Z","shell.execute_reply.started":"2024-08-02T16:16:29.553535Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]}],"source":["training_arguments = TrainingArguments(\n","    output_dir = '/kaggle/working',\n","    per_device_train_batch_size = 2,\n","    per_device_eval_batch_size = 2,\n","    gradient_checkpointing = True,\n","    gradient_accumulation_steps = 1,\n","    optim = 'paged_adamw_8bit',\n","    save_steps = 25,\n","    save_strategy = 'steps',\n","    evaluation_strategy = 'steps',\n","    eval_steps = 25,\n","    load_best_model_at_end = True,\n","    learning_rate = 2e-4,\n","    weight_decay = 0.001,\n","    fp16 = False,\n","    bf16 = False,\n","    max_grad_norm = 0.3,\n","    max_steps = -1,\n","    warmup_ratio = 0.03,\n","    group_by_length = True,\n","    lr_scheduler_type = 'cosine',\n","    report_to = 'tensorboard'\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:16:38.086260Z","iopub.status.busy":"2024-08-02T16:16:38.085888Z","iopub.status.idle":"2024-08-02T16:16:38.090684Z","shell.execute_reply":"2024-08-02T16:16:38.089666Z","shell.execute_reply.started":"2024-08-02T16:16:38.086232Z"},"trusted":true},"outputs":[],"source":["early_stopping = EarlyStoppingCallback(\n","    early_stopping_patience = 2,\n",")"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:18:24.005222Z","iopub.status.busy":"2024-08-02T16:18:24.004519Z","iopub.status.idle":"2024-08-02T16:18:24.265695Z","shell.execute_reply":"2024-08-02T16:18:24.264951Z","shell.execute_reply.started":"2024-08-02T16:18:24.005190Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:289: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:318: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"81b9cdeb113043688bf2984668ffdd7f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/150 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6c47252fc8cf4b02a8d520812cc85639","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/50 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Set supervised fine-tuning parameters\n","trainer = SFTTrainer(\n","    model = model, \n","    train_dataset = train_dataset,\n","    eval_dataset = eval_dataset,\n","    dataset_text_field = 'text',\n","    max_seq_length = None,\n","    tokenizer = tokenizer,\n","    args = training_arguments,\n","    callbacks = [early_stopping]\n",")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T16:18:30.727139Z","iopub.status.busy":"2024-08-02T16:18:30.726761Z","iopub.status.idle":"2024-08-02T17:21:16.628426Z","shell.execute_reply":"2024-08-02T17:21:16.627182Z","shell.execute_reply.started":"2024-08-02T16:18:30.727110Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='200' max='225' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [200/225 1:01:58 < 07:49, 0.05 it/s, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>25</td>\n","      <td>No log</td>\n","      <td>1.428499</td>\n","    </tr>\n","    <tr>\n","      <td>50</td>\n","      <td>No log</td>\n","      <td>1.281319</td>\n","    </tr>\n","    <tr>\n","      <td>75</td>\n","      <td>No log</td>\n","      <td>1.245929</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>No log</td>\n","      <td>1.235654</td>\n","    </tr>\n","    <tr>\n","      <td>125</td>\n","      <td>No log</td>\n","      <td>1.231044</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>No log</td>\n","      <td>1.230033</td>\n","    </tr>\n","    <tr>\n","      <td>175</td>\n","      <td>No log</td>\n","      <td>1.231645</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>No log</td>\n","      <td>1.232338</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"data":{"text/plain":["TrainOutput(global_step=200, training_loss=1.3957742309570313, metrics={'train_runtime': 3765.2712, 'train_samples_per_second': 0.12, 'train_steps_per_second': 0.06, 'total_flos': 7355697750294528.0, 'train_loss': 1.3957742309570313, 'epoch': 2.6666666666666665})"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["# Step 6: Testing"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-08-02T17:21:16.631655Z","iopub.status.busy":"2024-08-02T17:21:16.630360Z","iopub.status.idle":"2024-08-02T17:21:18.049450Z","shell.execute_reply":"2024-08-02T17:21:18.048536Z","shell.execute_reply.started":"2024-08-02T17:21:16.631626Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Prompt: Why did the chicken cross the road?\n","Model's response: Why did the chicken cross the road? To get to the other side!\n"]}],"source":["def generate_response(prompt, model, tokenizer, max_length=200):\n","    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n","    outputs = model.generate(**inputs, max_new_tokens=max_length, temperature=0.7, top_p=0.9)\n","    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    return response\n","\n","# Example usage\n","prompt = \"Why did the chicken cross the road?\"\n","response = generate_response(prompt, model, tokenizer)\n","print(f\"Prompt: {prompt}\")\n","print(f\"Model's response: {response}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
